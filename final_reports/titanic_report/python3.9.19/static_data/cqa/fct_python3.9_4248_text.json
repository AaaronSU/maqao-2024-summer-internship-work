{
  "_cqa_text_report":
    {
      "_objects":
        {
          "image_vec_align":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/vec_align.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_1x64_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x64_512.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_1x32_128":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x32_128.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_4x32_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/4x32_256.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_1x64_128":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x64_128.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_4x32_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/4x32_512.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_8x32_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/8x32_512.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_1x32_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x32_256.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_2x64_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/2x64_512.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_2x64_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/2x64_256.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_1x64_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x64_256.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_1x32_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x32_512.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_4x64_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/4x64_512.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_row_maj":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/row_maj.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_col_maj":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/col_maj.svg",
              "size":
                {
                  "x": 500,
                },
            },
        },
      "AVG":
        {
          "hint":
            [
              {
                "details": "These instructions generate more than one micro-operation and only one of them can be decoded during a cycle and the extra micro-operations increase pressure on execution units.\n - RET: 1 occurrences\n",
                "title": "Complex instructions",
                "txt": "Detected COMPLEX INSTRUCTIONS.\n",
              },
              {
                "title": "Type of elements and instruction set",
                "txt": "No instructions are processing arithmetic or math operations on FP elements. This function is probably writing/copying data or processing integer elements.",
              },
              {
                "title": "Matching between your function (in the source code) and the binary function",
                "txt": "The binary function does not contain any FP arithmetical operations.\nThe binary function does not load or store any data.",
              },
            ],
          "expert":
            [
              {
                "title": "General properties",
                "txt": "nb instructions    : 9\nnb uops            : 10\nloop length        : 50\nused x86 registers : 5\nused mmx registers : 0\nused xmm registers : 0\nused ymm registers : 0\nused zmm registers : 0\nnb stack references: 0\n",
              },
              {
                "title": "Front-end",
                "txt": "MACRO FUSION NOT POSSIBLE\nFIT IN UOP CACHE\nmicro-operation queue: 2.00 cycles\nfront end            : 2.00 cycles\n",
              },
              {
                "title": "Back-end",
                "txt": "       | P0   | P1   | P2   | P3   | P4   | P5   | P6   | P7   | P8   | P9\n----------------------------------------------------------------------------\nuops   | 1.50 | 1.50 | 1.00 | 1.00 | 1.00 | 1.50 | 1.50 | 1.00 | 1.00 | 1.00\ncycles | 1.50 | 1.50 | 1.00 | 1.00 | 1.00 | 1.50 | 1.50 | 1.00 | 1.00 | 1.00\n\nExecution ports to units layout:\n - P0 (256 bits): VPU, ALU, DIV/SQRT\n - P1 (256 bits): ALU, VPU\n - P2 (512 bits): load\n - P3 (512 bits): load\n - P4 (256 bits): store data\n - P5 (512 bits): ALU, VPU\n - P6: ALU\n - P7: store address\n - P8: store address\n - P9 (256 bits): store data\n\nCycles executing div or sqrt instructions: NA\n",
              },
              {
                "title": "Cycles summary",
                "txt": "Front-end : 2.00\nDispatch  : 1.50\nOverall L1: 2.00\n",
              },
              {
                "title": "Vectorization ratios",
                "txt": "all     : 0%\nload    : NA (no load vectorizable/vectorized instructions)\nstore   : NA (no store vectorizable/vectorized instructions)\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : NA (no add-sub vectorizable/vectorized instructions)\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : 0%\n",
              },
              {
                "title": "Vector efficiency ratios",
                "txt": "all     : 8%\nload    : NA (no load vectorizable/vectorized instructions)\nstore   : NA (no store vectorizable/vectorized instructions)\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : NA (no add-sub vectorizable/vectorized instructions)\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : 8%\n",
              },
              {
                "title": "Cycles and memory resources usage",
                "txt": "Assuming all data fit into the L1 cache, each call to the function takes 2.00 cycles. At this rate:\n",
              },
              {
                "title": "Front-end bottlenecks",
                "txt": "Performance is limited by instruction throughput (loading/decoding program instructions to execution core) (front-end is a bottleneck).\n\nBy removing all these bottlenecks, you can lower the cost of an iteration from 2.00 to 1.50 cycles (1.33x speedup).\n",
              },
              {
                "title": "ASM code",
                "txt": "In the binary file, the address of the function is: 4e09f0\n\nInstruction                | Nb FU | P0   | P1   | P2 | P3 | P4 | P5   | P6   | P7 | P8 | P9 | Latency | Recip. throughput\n--------------------------------------------------------------------------------------------------------------------------\nXOR %EDX,%EDX              | 1     | 0    | 0    | 0  | 0  | 0  | 0    | 0    | 0  | 0  | 0  | 0       | 0.25\nXOR %R8D,%R8D              | 1     | 0    | 0    | 0  | 0  | 0  | 0    | 0    | 0  | 0  | 0  | 0       | 0.25\nMOV $0x1,%R10D             | 1     | 0.25 | 0.25 | 0  | 0  | 0  | 0.25 | 0.25 | 0  | 0  | 0  | 1       | 0.25\nMOV $0x400104900000200,%R9 | 1     | 0.25 | 0.25 | 0  | 0  | 0  | 0.25 | 0.25 | 0  | 0  | 0  | 1       | 0.25\nMOV %R8,%RAX               | 1     | 0.25 | 0.25 | 0  | 0  | 0  | 0.25 | 0.25 | 0  | 0  | 0  | 1       | 0.25\nRET                        | 2     | 0.75 | 0.75 | 1  | 1  | 1  | 0.75 | 0.75 | 1  | 1  | 1  | 0       | 32\nNOPW (%RAX,%RAX,1)         | 1     | 0    | 0    | 0  | 0  | 0  | 0    | 0    | 0  | 0  | 0  | 0       | 0.20\nNOPL (%RAX)                | 1     | 0    | 0    | 0  | 0  | 0  | 0    | 0    | 0  | 0  | 0  | 0       | 0.20\nNOPW (%RAX,%RAX,1)         | 1     | 0    | 0    | 0  | 0  | 0  | 0    | 0    | 0  | 0  | 0  | 0       | 0.20\n",
              },
            ],
          "header":
            [
            "0% of peak computational performance is used (0.00 out of 64.00 FLOP per cycle (GFLOPS @ 1GHz))",
            ],
          "brief":
            [
            ],
          "gain":
            [
              {
                "workaround": " - Try another compiler or update/tune your current one\n - Make array accesses unit-stride:\n  * If your function streams arrays of structures (AoS), try to use structures of arrays instead (SoA):\nfor(i) a[i].x = b[i].x; (slow, non stride 1) => for(i) a.x[i] = b.x[i]; (fast, stride 1)\n",
                "details": "All SSE/AVX instructions are used in scalar version (process only one data element in vector registers).\nSince your execution units are vector units, only a vectorized function can use their full power.\n",
                "title": "Vectorization",
                "txt": "Your function is not vectorized.\nOnly 8% of vector register length is used (average across all SSE/AVX instructions).\nBy vectorizing your function, you can lower the cost of an iteration from 2.00 to 0.12 cycles (16.00x speedup).",
              },
              {
                "title": "Execution units bottlenecks",
                "txt": "Found no such bottlenecks but see expert reports for more complex bottlenecks.",
              },
            ],
          "potential":
            [
            ],
        },
      "paths":
        [
          {
            "hint":
              [
                {
                  "details": "These instructions generate more than one micro-operation and only one of them can be decoded during a cycle and the extra micro-operations increase pressure on execution units.\n - RET: 1 occurrences\n",
                  "title": "Complex instructions",
                  "txt": "Detected COMPLEX INSTRUCTIONS.\n",
                },
                {
                  "title": "Type of elements and instruction set",
                  "txt": "No instructions are processing arithmetic or math operations on FP elements. This function is probably writing/copying data or processing integer elements.",
                },
                {
                  "title": "Matching between your function (in the source code) and the binary function",
                  "txt": "The binary function does not contain any FP arithmetical operations.\nThe binary function does not load or store any data.",
                },
              ],
            "expert":
              [
                {
                  "title": "General properties",
                  "txt": "nb instructions    : 9\nnb uops            : 10\nloop length        : 50\nused x86 registers : 5\nused mmx registers : 0\nused xmm registers : 0\nused ymm registers : 0\nused zmm registers : 0\nnb stack references: 0\n",
                },
                {
                  "title": "Front-end",
                  "txt": "MACRO FUSION NOT POSSIBLE\nFIT IN UOP CACHE\nmicro-operation queue: 2.00 cycles\nfront end            : 2.00 cycles\n",
                },
                {
                  "title": "Back-end",
                  "txt": "       | P0   | P1   | P2   | P3   | P4   | P5   | P6   | P7   | P8   | P9\n----------------------------------------------------------------------------\nuops   | 1.50 | 1.50 | 1.00 | 1.00 | 1.00 | 1.50 | 1.50 | 1.00 | 1.00 | 1.00\ncycles | 1.50 | 1.50 | 1.00 | 1.00 | 1.00 | 1.50 | 1.50 | 1.00 | 1.00 | 1.00\n\nExecution ports to units layout:\n - P0 (256 bits): VPU, ALU, DIV/SQRT\n - P1 (256 bits): ALU, VPU\n - P2 (512 bits): load\n - P3 (512 bits): load\n - P4 (256 bits): store data\n - P5 (512 bits): ALU, VPU\n - P6: ALU\n - P7: store address\n - P8: store address\n - P9 (256 bits): store data\n\nCycles executing div or sqrt instructions: NA\n",
                },
                {
                  "title": "Cycles summary",
                  "txt": "Front-end : 2.00\nDispatch  : 1.50\nOverall L1: 2.00\n",
                },
                {
                  "title": "Vectorization ratios",
                  "txt": "all     : 0%\nload    : NA (no load vectorizable/vectorized instructions)\nstore   : NA (no store vectorizable/vectorized instructions)\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : NA (no add-sub vectorizable/vectorized instructions)\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : 0%\n",
                },
                {
                  "title": "Vector efficiency ratios",
                  "txt": "all     : 8%\nload    : NA (no load vectorizable/vectorized instructions)\nstore   : NA (no store vectorizable/vectorized instructions)\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : NA (no add-sub vectorizable/vectorized instructions)\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : 8%\n",
                },
                {
                  "title": "Cycles and memory resources usage",
                  "txt": "Assuming all data fit into the L1 cache, each call to the function takes 2.00 cycles. At this rate:\n",
                },
                {
                  "title": "Front-end bottlenecks",
                  "txt": "Performance is limited by instruction throughput (loading/decoding program instructions to execution core) (front-end is a bottleneck).\n\nBy removing all these bottlenecks, you can lower the cost of an iteration from 2.00 to 1.50 cycles (1.33x speedup).\n",
                },
                {
                  "title": "ASM code",
                  "txt": "In the binary file, the address of the function is: 4e09f0\n\nInstruction                | Nb FU | P0   | P1   | P2 | P3 | P4 | P5   | P6   | P7 | P8 | P9 | Latency | Recip. throughput\n--------------------------------------------------------------------------------------------------------------------------\nXOR %EDX,%EDX              | 1     | 0    | 0    | 0  | 0  | 0  | 0    | 0    | 0  | 0  | 0  | 0       | 0.25\nXOR %R8D,%R8D              | 1     | 0    | 0    | 0  | 0  | 0  | 0    | 0    | 0  | 0  | 0  | 0       | 0.25\nMOV $0x1,%R10D             | 1     | 0.25 | 0.25 | 0  | 0  | 0  | 0.25 | 0.25 | 0  | 0  | 0  | 1       | 0.25\nMOV $0x400104900000200,%R9 | 1     | 0.25 | 0.25 | 0  | 0  | 0  | 0.25 | 0.25 | 0  | 0  | 0  | 1       | 0.25\nMOV %R8,%RAX               | 1     | 0.25 | 0.25 | 0  | 0  | 0  | 0.25 | 0.25 | 0  | 0  | 0  | 1       | 0.25\nRET                        | 2     | 0.75 | 0.75 | 1  | 1  | 1  | 0.75 | 0.75 | 1  | 1  | 1  | 0       | 32\nNOPW (%RAX,%RAX,1)         | 1     | 0    | 0    | 0  | 0  | 0  | 0    | 0    | 0  | 0  | 0  | 0       | 0.20\nNOPL (%RAX)                | 1     | 0    | 0    | 0  | 0  | 0  | 0    | 0    | 0  | 0  | 0  | 0       | 0.20\nNOPW (%RAX,%RAX,1)         | 1     | 0    | 0    | 0  | 0  | 0  | 0    | 0    | 0  | 0  | 0  | 0       | 0.20\n",
                },
              ],
            "header":
              [
              "0% of peak computational performance is used (0.00 out of 64.00 FLOP per cycle (GFLOPS @ 1GHz))",
              ],
            "brief":
              [
              ],
            "gain":
              [
                {
                  "workaround": " - Try another compiler or update/tune your current one\n - Make array accesses unit-stride:\n  * If your function streams arrays of structures (AoS), try to use structures of arrays instead (SoA):\nfor(i) a[i].x = b[i].x; (slow, non stride 1) => for(i) a.x[i] = b.x[i]; (fast, stride 1)\n",
                  "details": "All SSE/AVX instructions are used in scalar version (process only one data element in vector registers).\nSince your execution units are vector units, only a vectorized function can use their full power.\n",
                  "title": "Vectorization",
                  "txt": "Your function is not vectorized.\nOnly 8% of vector register length is used (average across all SSE/AVX instructions).\nBy vectorizing your function, you can lower the cost of an iteration from 2.00 to 0.12 cycles (16.00x speedup).",
                },
                {
                  "title": "Execution units bottlenecks",
                  "txt": "Found no such bottlenecks but see expert reports for more complex bottlenecks.",
                },
              ],
            "potential":
              [
              ],
          },
        ],
      "common":
        {
          "header":
            [
            "The function is defined in /usr/local/src/conda/python-3.9.19/Python/modsupport.c:46-49,58-67,76-83.\n",
            "Warnings:\nget_cqa_results:\n - Ignoring paths for analysis\n",
            ],
        },
    },
}
